# LSM Tree：写优化存储引擎

## 核心设计

```
┌────────────────────────────────────────────────────────┐
│ Log-Structured Merge Tree                              │
├────────────────────────────────────────────────────────┤
│                                                        │
│  写入 → MemTable(内存) → 写满后刷入 SSTable(磁盘)       │
│                                                        │
│  ┌─────────────┐                                       │
│  │  MemTable   │ ← 所有写入先到内存（极快）             │
│  └──────┬──────┘                                       │
│         │ flush                                        │
│  ┌──────▼──────┐                                       │
│  │ Level 0 SST │ ← 不可变的有序文件                    │
│  ├─────────────┤                                       │
│  │ Level 1 SST │ ← 后台合并压缩                        │
│  ├─────────────┤                                       │
│  │ Level 2 SST │                                       │
│  └─────────────┘                                       │
│                                                        │
│  写入：O(1) 顺序写                                      │
│  读取：可能需要查多层（用 Bloom Filter 优化）            │
│                                                        │
└────────────────────────────────────────────────────────┘
```

## 为什么 LSM Tree 写入快？

```
┌────────────────────────────────────────────────────────┐
│ 磁盘 I/O 特性                                          │
├────────────────────────────────────────────────────────┤
│                                                        │
│  顺序写 vs 随机写：                                    │
│  • HDD 顺序写：100+ MB/s                              │
│  • HDD 随机写：< 1 MB/s  (差 100 倍)                  │
│  • SSD 顺序写：500+ MB/s                              │
│  • SSD 随机写：50+ MB/s  (差 10 倍)                   │
│                                                        │
│  B+ 树：随机写（更新叶子节点）                          │
│  LSM：顺序写（追加日志 + 批量刷盘）                     │
│                                                        │
└────────────────────────────────────────────────────────┘
```

## 写入流程

```
┌────────────────────────────────────────────────────────┐
│ 写入路径                                               │
├────────────────────────────────────────────────────────┤
│                                                        │
│  1. 写 WAL（Write-Ahead Log）                         │
│     └── 崩溃恢复用，顺序写                             │
│                                                        │
│  2. 写 MemTable（内存中的有序结构）                    │
│     └── 通常是跳表或红黑树                             │
│                                                        │
│  3. MemTable 满了 → 变成 Immutable MemTable           │
│     └── 新 MemTable 接收写入                          │
│                                                        │
│  4. 后台将 Immutable MemTable 刷入 Level 0 SSTable    │
│     └── SSTable = Sorted String Table，不可变         │
│                                                        │
└────────────────────────────────────────────────────────┘
```

```
写入请求
    │
    ▼
┌─────────┐     ┌─────────────┐
│   WAL   │────►│  MemTable   │ (活跃，接收写入)
└─────────┘     └──────┬──────┘
                       │ 满了
                       ▼
                ┌─────────────┐
                │  Immutable  │ (冻结，等待刷盘)
                │  MemTable   │
                └──────┬──────┘
                       │ flush
                       ▼
                ┌─────────────┐
                │  SSTable    │ (磁盘，不可变)
                │  Level 0    │
                └─────────────┘
```

## 读取流程

```
┌────────────────────────────────────────────────────────┐
│ 读取路径                                               │
├────────────────────────────────────────────────────────┤
│                                                        │
│  查找 key：                                            │
│                                                        │
│  1. 查 MemTable                                       │
│     └── 最新数据在这里                                 │
│                                                        │
│  2. 查 Immutable MemTable（如果有）                   │
│                                                        │
│  3. 从 Level 0 开始查 SSTable                         │
│     └── Level 0 的 SSTable 之间可能有重叠              │
│     └── 每层都用 Bloom Filter 先过滤                  │
│                                                        │
│  4. 逐层向下查找，直到找到或确认不存在                  │
│                                                        │
│  优化：                                                │
│  • Bloom Filter：快速判断 key 不在某个 SSTable        │
│  • 索引块：快速定位 key 所在的数据块                   │
│  • 块缓存：缓存热点数据块                              │
│                                                        │
└────────────────────────────────────────────────────────┘
```

## Compaction（压缩合并）

```
┌────────────────────────────────────────────────────────┐
│ 为什么需要 Compaction？                                │
├────────────────────────────────────────────────────────┤
│                                                        │
│  问题：                                                │
│  • SSTable 越来越多，读取要查很多文件                  │
│  • 同一个 key 可能有多个版本（更新/删除）               │
│  • 空间浪费（已删除的数据还在）                        │
│                                                        │
│  解决：后台合并 SSTable                                │
│  • 合并多个文件为一个                                  │
│  • 只保留每个 key 的最新版本                          │
│  • 清理已删除的数据（墓碑）                            │
│                                                        │
└────────────────────────────────────────────────────────┘
```

### Leveled Compaction（LevelDB/RocksDB 默认）

```
┌────────────────────────────────────────────────────────┐
│ 分层压缩                                               │
├────────────────────────────────────────────────────────┤
│                                                        │
│  Level 0: SSTable 之间可能重叠                        │
│           大小限制：4 个文件                           │
│                                                        │
│  Level 1+: SSTable 之间不重叠（有序分区）              │
│           每层大小 = 上一层 × 10                       │
│                                                        │
│  Level 0:  [====]  [====]  [====]  (重叠)            │
│                 ↓ compaction                          │
│  Level 1:  [==][==][==][==][==]    (不重叠)          │
│                 ↓ compaction                          │
│  Level 2:  [=][=][=][=][=][=][=][=][=][=]            │
│                                                        │
│  优点：空间放大小（约 1.1x）                           │
│  缺点：写放大大（约 10-30x）                           │
│                                                        │
└────────────────────────────────────────────────────────┘
```

### Size-Tiered Compaction（Cassandra 默认）

```
┌────────────────────────────────────────────────────────┐
│ 大小分层压缩                                           │
├────────────────────────────────────────────────────────┤
│                                                        │
│  相似大小的 SSTable 合并在一起                         │
│                                                        │
│  小文件: [=] [=] [=] [=] → 合并 → [====]             │
│                                                        │
│  中文件: [====] [====] [====] → 合并 → [============] │
│                                                        │
│  优点：写放大小                                        │
│  缺点：空间放大大（可能 2x），读取查更多文件            │
│                                                        │
└────────────────────────────────────────────────────────┘
```

## SSTable 结构

```
┌────────────────────────────────────────────────────────┐
│ SSTable 文件格式                                       │
├────────────────────────────────────────────────────────┤
│                                                        │
│  ┌─────────────────────────────────────┐              │
│  │  Data Block 1                       │              │
│  │  [key1:value1][key2:value2]...     │              │
│  ├─────────────────────────────────────┤              │
│  │  Data Block 2                       │              │
│  │  [key3:value3][key4:value4]...     │              │
│  ├─────────────────────────────────────┤              │
│  │  ...                                │              │
│  ├─────────────────────────────────────┤              │
│  │  Meta Block (Bloom Filter)          │              │
│  ├─────────────────────────────────────┤              │
│  │  Index Block                        │              │
│  │  [block1_last_key → offset]        │              │
│  │  [block2_last_key → offset]        │              │
│  ├─────────────────────────────────────┤              │
│  │  Footer (指向 Index 和 Meta)        │              │
│  └─────────────────────────────────────┘              │
│                                                        │
│  查找过程：                                            │
│  1. 读 Footer → 找到 Index Block                      │
│  2. 二分查找 Index → 定位 Data Block                  │
│  3. 读取 Data Block → 找到 key                        │
│                                                        │
└────────────────────────────────────────────────────────┘
```

## 放大问题

```
┌────────────────────────────────────────────────────────┐
│ 三种放大                                               │
├────────────────────────────────────────────────────────┤
│                                                        │
│  写放大（Write Amplification）：                       │
│  • 写入 1 字节数据，实际写磁盘 N 字节                  │
│  • 原因：Compaction 重复写入数据                       │
│  • LSM 典型值：10-30x                                 │
│                                                        │
│  读放大（Read Amplification）：                        │
│  • 读取 1 个 key，实际读磁盘 N 次                     │
│  • 原因：需要查多层 SSTable                           │
│  • 优化：Bloom Filter、缓存                           │
│                                                        │
│  空间放大（Space Amplification）：                     │
│  • 存储 1 字节数据，实际占用 N 字节空间                │
│  • 原因：旧版本数据、墓碑、Compaction 临时空间         │
│  • Leveled: ~1.1x, Size-Tiered: ~2x                  │
│                                                        │
└────────────────────────────────────────────────────────┘
```

## 实际应用

```
┌────────────────────────────────────────────────────────┐
│ 使用 LSM Tree 的系统                                   │
├────────────────────────────────────────────────────────┤
│                                                        │
│  LevelDB     - Google，嵌入式 KV                      │
│  RocksDB     - Facebook，LevelDB 增强版               │
│  Cassandra   - 分布式宽列存储                         │
│  HBase       - Hadoop 生态 KV                         │
│  ClickHouse  - 列式分析数据库（MergeTree）            │
│  TiKV        - TiDB 存储引擎                          │
│  CockroachDB - 分布式 SQL                             │
│  ScyllaDB    - C++ 重写的 Cassandra                  │
│  InfluxDB    - 时序数据库（TSM = LSM 变种）           │
│  BadgerDB    - Go 实现的 KV                          │
│                                                        │
└────────────────────────────────────────────────────────┘
```

## LSM vs B+ Tree

```
┌────────────────────────────────────────────────────────┐
│ 对比                                                   │
├────────────────────────────────────────────────────────┤
│                                                        │
│              │  LSM Tree       │  B+ Tree             │
│  ────────────┼─────────────────┼──────────────────    │
│  写入性能     │  极好（顺序写）  │  较差（随机写）      │
│  读取性能     │  较差（多层查找）│  较好（一次定位）    │
│  范围查询     │  较差           │  好（叶子链表）      │
│  空间效率     │  较好（压缩）    │  一般（碎片）       │
│  写放大       │  高             │  低                 │
│  适用场景     │  写多读少       │  读多写少            │
│                                                        │
│  MySQL InnoDB: B+ Tree                                │
│  RocksDB:      LSM Tree                               │
│  TiDB:         LSM (TiKV) + B+ Tree (TiFlash)        │
│                                                        │
└────────────────────────────────────────────────────────┘
```

## 设计启示

1. **顺序写优于随机写** - 利用磁盘特性
2. **延迟合并** - 写入时不立即整理，后台批量处理
3. **不可变数据** - SSTable 不可变，简化并发
4. **分层存储** - 热数据在内存/上层，冷数据在下层
5. **空间换时间（或反之）** - 不同 Compaction 策略权衡
